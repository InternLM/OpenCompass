internlm2_5-7b-chat-hf_fullbench:
    race-high: 93.75
    ARC-c: 93.75
    BoolQ: 81.25
    triviaqa_wiki_1shot: 50
    nq_open_1shot: 25
    IFEval: 50
    drop: 81.25
    GPQA_diamond: 25
    hellaswag: 87.5
    TheoremQA: 18.75
    musr_average: 39.58
    gsm8k: 62.50
    math: 75
    cmo_fib: 6.25
    aime2024: 6.25
    wikibench-wiki-single_choice_cncircular: 50
    sanitized_mbpp: 68.75
    ds1000: 16.96
    lcb_code_generation: 12.5
    lcb_code_execution: 43.75
    lcb_test_output: 18.75
    bbh-logical_deduction_seven_objects: 50
    bbh-multistep_arithmetic_two: 68.75
    mmlu-other: 72.6
    cmmlu-china-specific: 76.25
    mmlu_pro_math: 25
    ds1000_Pandas: 12.5
    ds1000_Numpy: 0
    ds1000_Tensorflow: 12.5
    ds1000_Scipy: 18.75
    ds1000_Sklearn: 18.75
    ds1000_Pytorch: 12.5
    ds1000_Matplotlib: 43.75
    openai_mmmlu_lite_AR-XY: 37.5
    college: 12.5
    college_knowledge: 87.5
    Alignbench总分: 0.65
    Alignbench专业能力: 7.83
    AlpacaEvaltotal: 0
    AlpacaEvalhelpful_base: 0
    CompassArenacompassarena_language: 60
    CompassArenacompassarena_knowledge: 56
    CompassArenacompassarena_reason_v2: 50
    CompassArenacompassarena_math_v2: 53.5
    CompassArenacompassarena_creationv2_zh: 48.75
    Fofofofo_test_prompts: 1
    followbenchHSR_AVG: 1
    followbenchSSR_AVG: 1
    followbenchHSR_L1: 1
    followbenchHSR_L2: 1
    followbenchHSR_L3: 1
    followbenchHSR_L4: 1
    followbenchHSR_L5: 1
    followbenchSSR_L1: 1
    followbenchSSR_L2: 1
    followbenchSSR_L3: 1
    followbenchSSR_L4: 1
    followbenchSSR_L5: 1
    MTBench101average: 8.1
    Wildbenchscore: -3.3333333333333335

internlm2_5-7b-chat-turbomind_fullbench:
    race-high: 93.75
    ARC-c: 87.5
    BoolQ: 68.75
    triviaqa_wiki_1shot: 50
    nq_open_1shot: 25
    IFEval: 50
    drop: 75
    hellaswag: 81.25
    TheoremQA: 6.25
    musr_average: 37.5
    gsm8k: 68.75
    math: 75
    GPQA_diamond: 25
    cmo_fib: 6.25
    aime2024: 6.25
    wikibench-wiki-single_choice_cncircular: 25
    sanitized_mbpp: 68.75
    ds1000: 13.39
    lcb_code_generation: 12.5
    lcb_code_execution: 43.75
    lcb_test_output: 12.5
    bbh-logical_deduction_seven_objects: 56.25
    bbh-multistep_arithmetic_two: 68.75
    mmlu-other: 74.04
    cmmlu-china-specific: 76.25
    mmlu_pro_math: 25
    ds1000_Pandas: 0
    ds1000_Numpy: 0
    ds1000_Tensorflow: 12.5
    ds1000_Scipy: 18.75
    ds1000_Sklearn: 18.75
    ds1000_Pytorch: 6.25
    ds1000_Matplotlib: 37.5
    openai_mmmlu_lite_AR-XY: 37.5
    college: 0
    college_knowledge: 87.5
    Alignbench总分: 0.64
    Alignbench专业能力: 7.6
    AlpacaEvaltotal: 10
    AlpacaEvalhelpful_base: 10
    CompassArenacompassarena_language: 59
    CompassArenacompassarena_knowledge: 57
    CompassArenacompassarena_reason_v2: 49.5
    CompassArenacompassarena_math_v2: 51
    CompassArenacompassarena_creationv2_zh: 43.75
    Fofofofo_test_prompts: 1
    followbenchHSR_AVG: 1
    followbenchSSR_AVG: 1
    followbenchHSR_L1: 1
    followbenchHSR_L2: 1
    followbenchHSR_L3: 1
    followbenchHSR_L4: 1
    followbenchHSR_L5: 1
    followbenchSSR_L1: 1
    followbenchSSR_L2: 1
    followbenchSSR_L3: 1
    followbenchSSR_L4: 1
    followbenchSSR_L5: 1
    MTBench101average: 8.1
    Wildbenchscore: -8.333333333333334

internlm2_5-7b-hf_fullbench:
    race-high: 100
    ARC-c: 68.75
    BoolQ: 87.5
    triviaqa_wiki_1shot: 43.75
    nq_open_1shot: 43.75
    drop: 62.5
    GPQA_diamond: 62.5
    hellaswag: 93.75
    TheoremQA: 25
    winogrande: 75
    gsm8k: 37.5
    math: 12.5
    wikibench-wiki-single_choice_cncircular: 25
    sanitized_mbpp: 56.25
    dingo_en_192: 37.5
    dingo_zh_170: 100
    college: 12.5
    college_knowledge: 87.5
    bbh-logical_deduction_seven_objects: 43.75
    bbh-multistep_arithmetic_two: 56.25
    mmlu-other: 76.92
    cmmlu-china-specific: 84.17
    mmlu_pro_math: 18.75

internlm2_5-7b-turbomind_fullbench:
    race-high: 100
    ARC-c: 68.75
    BoolQ: 87.5
    triviaqa_wiki_1shot: 43.75
    nq_open_1shot: 43.75
    drop: 62.5
    GPQA_diamond: 62.5
    hellaswag: 93.75
    TheoremQA: 31.25
    winogrande: 87.5
    gsm8k: 68.75
    math: 18.75
    wikibench-wiki-single_choice_cncircular: 25
    sanitized_mbpp: 56.25
    dingo_en_192: 43.75
    dingo_zh_170: 100
    college: 12.5
    college_knowledge: 87.5
    bbh-logical_deduction_seven_objects: 50
    bbh-multistep_arithmetic_two: 56.25
    mmlu-other: 76.92
    cmmlu-china-specific: 84.17
    mmlu_pro_math: 18.75



internlm2_5-7b-chat-turbomind:
    race-high: 86.16
    ARC-c: 90.17
    BoolQ: 87.89
    triviaqa_wiki_1shot: 64.91
    nq_open_1shot: 22.69
    mmmlu_lite: 44.96
    IFEval: 58.04
    drop: 77.68
    bbh: 73.14
    GPQA_diamond: 25.76
    hellaswag: 94.79
    TheoremQA: 21.5
    musr_average: 51.03
    korbench_single: 31.92
    ARC_Prize_Public_Evaluation: 0.01
    gsm8k: 86.73
    GaokaoBench: 77.89
    math: 61.5
    cmo_fib: 12.5
    aime2024: 3.33
    Mathbench: 65.17
    wikibench-wiki-single_choice_cncircular: 31.55
    cmmlu: 74.14
    mmlu: 70.52
    mmlu_pro: 44.98
    openai_humaneval: 70.73
    sanitized_mbpp: 63.81
    humanevalx: 38.17
    ds1000: 14.15
    lcb_code_generation: 17.75
    lcb_code_execution: 32.57
    lcb_test_output: 24.89
    bigcodebench_hard_instruct: 0.08
    bigcodebench_hard_complete: 0.06
    teval: 80.03
    qa_dingo_cn: 99.01
    mmlu-stem: 68.2
    mmlu-social-science: 76.11
    mmlu-humanities: 68.71
    mmlu-other: 70.56
    cmmlu-stem: 66.27
    cmmlu-social-science: 75.7
    cmmlu-humanities: 77.7
    cmmlu-other: 77.71
    cmmlu-china-specific: 72.94
    mmlu_pro_biology: 66.25
    mmlu_pro_business: 48.42
    mmlu_pro_chemistry: 35.25
    mmlu_pro_computer_science: 47.56
    mmlu_pro_economics: 55.92
    mmlu_pro_engineering: 30.44
    mmlu_pro_health: 45.97
    mmlu_pro_history: 41.21
    mmlu_pro_law: 25.79
    mmlu_pro_math: 54.03
    mmlu_pro_philosophy: 36.47
    mmlu_pro_physics: 37.41
    mmlu_pro_psychology: 58.77
    mmlu_pro_other: 46.21
    humanevalx-python: 53.66
    humanevalx-cpp: 24.39
    humanevalx-go: 0
    humanevalx-java: 57.93
    humanevalx-js: 54.88
    ds1000_Pandas: 12.03
    ds1000_Numpy: 4.09
    ds1000_Tensorflow: 11.11
    ds1000_Scipy: 8.49
    ds1000_Sklearn: 6.96
    ds1000_Pytorch: 7.35
    ds1000_Matplotlib: 49.03
    openai_mmmlu_lite_AR-XY: 17.89
    openai_mmmlu_lite_BN-BD: 27.58
    openai_mmmlu_lite_DE-DE: 51.16
    openai_mmmlu_lite_ES-LA: 56.84
    openai_mmmlu_lite_FR-FR: 57.96
    openai_mmmlu_lite_HI-IN: 33.68
    openai_mmmlu_lite_ID-ID: 51.02
    openai_mmmlu_lite_IT-IT: 50.46
    openai_mmmlu_lite_JA-JP: 50.53
    openai_mmmlu_lite_KO-KR: 45.05
    openai_mmmlu_lite_PT-BR: 57.68
    openai_mmmlu_lite_SW-KE: 32.77
    openai_mmmlu_lite_YO-NG: 31.79
    openai_mmmlu_lite_ZH-CN: 65.05
    college: 20.33
    high: 47.67
    middle: 62
    primary: 72
    arithmetic: 62.33
    mathbench-a (average): 52.87
    college_knowledge: 70.57
    high_knowledge: 70.13
    middle_knowledge: 81.17
    primary_knowledge: 88.01
    mathbench-t (average): 77.47
    alignment_bench_v1_1_总分: 5.68
    alpaca_eval_total: 25.96
    arenahard_score: 17.15
    Followbench_naive_average: 0.81
    CompassArena_naive_average: 34.61
    FoFo_naive_average: 0.38
    mtbench101_avg: 8.01
    wildbench_average: -15.69
    simpleqa_accuracy_given_attempted: 0.04
    chinese_simpleqa_given_attempted_accuracy: 0.34
    alignment_bench_v1_1_专业能力: 6.05
    alignment_bench_v1_1_数学计算: 5.87
    alignment_bench_v1_1_基本任务: 6.01
    alignment_bench_v1_1_逻辑推理: 4.48
    alignment_bench_v1_1_中文理解: 6.17
    alignment_bench_v1_1_文本写作: 6.06
    alignment_bench_v1_1_角色扮演: 6.3
    alignment_bench_v1_1_综合问答: 6.45
    alpaca_eval_helpful_base: 17.83
    alpaca_eval_koala: 28.21
    alpaca_eval_oasst: 23.4
    alpaca_eval_selfinstruct: 30.95
    alpaca_eval_vicuna: 25
    compassarena_language_naive_average: 52.5
    compassarena_knowledge_naive_average: 36
    compassarena_reason_v2_naive_average: 35
    compassarena_math_v2_naive_average: 19.91
    compassarena_creationv2_zh_naive_average: 29.64
    fofo_test_prompts_overall: 0.35
    fofo_test_prompts_cn_overall: 0.41
    followbench_llmeval_en_HSR_AVG: 0.73
    followbench_llmeval_en_SSR_AVG: 0.88
    followbench_llmeval_en_HSR_L1: 0.94
    followbench_llmeval_en_HSR_L2: 0.77
    followbench_llmeval_en_HSR_L3: 0.73
    followbench_llmeval_en_HSR_L4: 0.68
    followbench_llmeval_en_HSR_L5: 0.54
    followbench_llmeval_en_SSR_L1: 0.94
    followbench_llmeval_en_SSR_L2: 0.88
    followbench_llmeval_en_SSR_L3: 0.87
    followbench_llmeval_en_SSR_L4: 0.87
    followbench_llmeval_en_SSR_L5: 0.85
    simpleqa_f1: 0.04
