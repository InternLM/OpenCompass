07/03 13:55:52 - OpenCompass - INFO - Task [chatglm3-6b-hf2/mtbench101]
/mnt/petrelfs/caomaosong/miniconda3/envs/opencompass/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm3-6b:
- tokenization_chatglm.py
. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.
Setting eos_token is not supported, use the default one.
Setting pad_token is not supported, use the default one.
Setting unk_token is not supported, use the default one.
A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm3-6b:
- configuration_chatglm.py
. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.
A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm3-6b:
- modeling_chatglm.py
. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.

Downloading shards:   0%|          | 0/7 [00:00<?, ?it/s]
Downloading shards: 100%|██████████| 7/7 [00:00<00:00, 525.49it/s]

Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]
Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:04,  1.35it/s]
Loading checkpoint shards:  29%|██▊       | 2/7 [00:01<00:03,  1.30it/s]
Loading checkpoint shards:  43%|████▎     | 3/7 [00:02<00:03,  1.32it/s]
Loading checkpoint shards:  57%|█████▋    | 4/7 [00:03<00:02,  1.27it/s]
Loading checkpoint shards:  71%|███████▏  | 5/7 [00:03<00:01,  1.30it/s]
Loading checkpoint shards:  86%|████████▌ | 6/7 [00:04<00:00,  1.29it/s]
Loading checkpoint shards: 100%|██████████| 7/7 [00:05<00:00,  1.47it/s]
Loading checkpoint shards: 100%|██████████| 7/7 [00:05<00:00,  1.37it/s]
07/03 13:56:10 - OpenCompass - INFO - Start inferencing [chatglm3-6b-hf2/mtbench101]
[2024-07-03 13:56:10,230] [opencompass.openicl.icl_inferencer.icl_chat_inferencer] [INFO] Starting inference process...

  0%|          | 0/19 [00:00<?, ?it/s]Both `max_new_tokens` (=4096) and `max_length`(=8192) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)

  5%|▌         | 1/19 [00:02<00:48,  2.68s/it]Both `max_new_tokens` (=4096) and `max_length`(=8192) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)

 11%|█         | 2/19 [00:03<00:27,  1.61s/it]Both `max_new_tokens` (=4096) and `max_length`(=8192) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)

 16%|█▌        | 3/19 [00:03<00:16,  1.06s/it]Both `max_new_tokens` (=4096) and `max_length`(=8192) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)

 21%|██        | 4/19 [00:04<00:10,  1.38it/s]Both `max_new_tokens` (=4096) and `max_length`(=8192) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)

 26%|██▋       | 5/19 [00:04<00:07,  1.87it/s]Both `max_new_tokens` (=4096) and `max_length`(=8192) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)

 32%|███▏      | 6/19 [00:04<00:05,  2.34it/s]Both `max_new_tokens` (=4096) and `max_length`(=8192) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)

 37%|███▋      | 7/19 [00:04<00:04,  2.71it/s]Both `max_new_tokens` (=4096) and `max_length`(=8192) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)

 42%|████▏     | 8/19 [00:06<00:08,  1.33it/s]Both `max_new_tokens` (=4096) and `max_length`(=8192) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)

 47%|████▋     | 9/19 [00:07<00:09,  1.06it/s]Both `max_new_tokens` (=4096) and `max_length`(=8192) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)

 53%|█████▎    | 10/19 [00:08<00:07,  1.15it/s]Both `max_new_tokens` (=4096) and `max_length`(=8192) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)

 58%|█████▊    | 11/19 [00:09<00:07,  1.13it/s]Both `max_new_tokens` (=4096) and `max_length`(=8192) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)

 63%|██████▎   | 12/19 [00:10<00:05,  1.17it/s]Both `max_new_tokens` (=4096) and `max_length`(=8192) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)

 68%|██████▊   | 13/19 [00:11<00:06,  1.08s/it]Both `max_new_tokens` (=4096) and `max_length`(=8192) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)

 74%|███████▎  | 14/19 [00:13<00:05,  1.19s/it]Both `max_new_tokens` (=4096) and `max_length`(=8192) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)

 79%|███████▉  | 15/19 [00:14<00:04,  1.15s/it]Both `max_new_tokens` (=4096) and `max_length`(=8192) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)

 84%|████████▍ | 16/19 [00:14<00:02,  1.09it/s]Both `max_new_tokens` (=4096) and `max_length`(=8192) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)

 89%|████████▉ | 17/19 [00:15<00:01,  1.22it/s]Both `max_new_tokens` (=4096) and `max_length`(=8192) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)

 95%|█████████▍| 18/19 [00:16<00:01,  1.00s/it]Both `max_new_tokens` (=4096) and `max_length`(=8192) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)

100%|██████████| 19/19 [00:18<00:00,  1.24s/it]
100%|██████████| 19/19 [00:18<00:00,  1.03it/s]
07/03 13:56:28 - OpenCompass - INFO - time elapsed: 35.85s
