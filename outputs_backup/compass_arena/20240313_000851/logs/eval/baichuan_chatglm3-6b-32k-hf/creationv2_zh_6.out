{'abbr': 'baichuan', 'batch_size': 1, 'generation_kwargs': {'do_sample': True}, 'max_out_len': 2048, 'max_seq_len': 4096, 'meta_template': {'reserved_roles': [{'api_role': 'SYSTEM', 'role': 'SYSTEM'}], 'round': [{'api_role': 'HUMAN', 'role': 'HUMAN'}, {'api_role': 'BOT', 'generate': True, 'role': 'BOT'}]}, 'model_kwargs': {'device_map': 'auto', 'trust_remote_code': True}, 'path': 'THUDM/chatglm3-6b', 'run_cfg': {'num_gpus': 1, 'num_procs': 1}, 'tokenizer_kwargs': {'padding_side': 'left', 'truncation_side': 'left', 'trust_remote_code': True}, 'tokenizer_path': 'THUDM/chatglm3-6b', 'type': 'opencompass.models.HuggingFaceChatGLM3'}
{'abbr': 'chatglm3-6b-32k-hf', 'batch_size': 1, 'generation_kwargs': {'do_sample': True}, 'max_out_len': 2048, 'max_seq_len': 4096, 'meta_template': {'reserved_roles': [{'api_role': 'SYSTEM', 'role': 'SYSTEM'}], 'round': [{'api_role': 'HUMAN', 'role': 'HUMAN'}, {'api_role': 'BOT', 'generate': True, 'role': 'BOT'}]}, 'model_kwargs': {'device_map': 'auto', 'trust_remote_code': True}, 'path': 'THUDM/chatglm3-6b', 'run_cfg': {'num_gpus': 1, 'num_procs': 1}, 'tokenizer_kwargs': {'padding_side': 'left', 'truncation_side': 'left', 'trust_remote_code': True}, 'tokenizer_path': 'THUDM/chatglm3-6b', 'type': 'opencompass.models.HuggingFaceChatGLM3'}
03/13 00:20:35 - OpenCompass - [4m[97mINFO[0m - Task [baichuan_chatglm3-6b-32k-hf/creationv2_zh_6]
03/13 00:20:35 - OpenCompass - [4m[97mINFO[0m - time elapsed: 46.05s
srun: job 3472316 queued and waiting for resources
srun: job 3472316 has been allocated resources
srun: Job 3472316 scheduled successfully!
Current QUOTA_TYPE is [spot], which means the job has occupied quota in SPOT_TOTAL under your partition.
[NOTE]: This job MAY BE PREEMPTED by other jobs of reserved QUOTA_TYPE.
[NOTE]: phx_priority has NO effect on job of spot quota type.

/mnt/petrelfs/caomaosong/miniconda3/envs/opencompass/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm3-6b:
- tokenization_chatglm.py
. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.
A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm3-6b:
- configuration_chatglm.py
. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.
A new version of the following files was downloaded from https://huggingface.co/THUDM/chatglm3-6b:
- modeling_chatglm.py
. Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.

Downloading shards:   0%|          | 0/7 [00:00<?, ?it/s]
Downloading shards: 100%|██████████| 7/7 [00:00<00:00, 600.13it/s]

Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]
Loading checkpoint shards:  14%|█▍        | 1/7 [00:01<00:06,  1.07s/it]
Loading checkpoint shards:  29%|██▊       | 2/7 [00:02<00:05,  1.12s/it]
Loading checkpoint shards:  43%|████▎     | 3/7 [00:03<00:04,  1.11s/it]
Loading checkpoint shards:  57%|█████▋    | 4/7 [00:04<00:03,  1.09s/it]
Loading checkpoint shards:  71%|███████▏  | 5/7 [00:05<00:02,  1.11s/it]
Loading checkpoint shards:  86%|████████▌ | 6/7 [00:06<00:01,  1.11s/it]
Loading checkpoint shards: 100%|██████████| 7/7 [00:07<00:00,  1.05it/s]
Loading checkpoint shards: 100%|██████████| 7/7 [00:07<00:00,  1.04s/it]
[2024-03-13 00:20:04,880] [opencompass.openicl.icl_inferencer.icl_gen_inferencer] [INFO] Starting inference process...

  0%|          | 0/15 [00:00<?, ?it/s]Both `max_new_tokens` (=2048) and `max_length`(=8192) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)

  7%|▋         | 1/15 [00:03<00:46,  3.34s/it]Both `max_new_tokens` (=2048) and `max_length`(=8192) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)

 13%|█▎        | 2/15 [00:06<00:40,  3.14s/it]Both `max_new_tokens` (=2048) and `max_length`(=8192) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)

 20%|██        | 3/15 [00:07<00:28,  2.39s/it]Both `max_new_tokens` (=2048) and `max_length`(=8192) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)

 27%|██▋       | 4/15 [00:09<00:24,  2.23s/it]Both `max_new_tokens` (=2048) and `max_length`(=8192) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)

 33%|███▎      | 5/15 [00:12<00:23,  2.31s/it]Both `max_new_tokens` (=2048) and `max_length`(=8192) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)

 40%|████      | 6/15 [00:12<00:15,  1.75s/it]Both `max_new_tokens` (=2048) and `max_length`(=8192) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)

 47%|████▋     | 7/15 [00:15<00:16,  2.04s/it]Both `max_new_tokens` (=2048) and `max_length`(=8192) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)

 53%|█████▎    | 8/15 [00:16<00:12,  1.77s/it]Both `max_new_tokens` (=2048) and `max_length`(=8192) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)

 60%|██████    | 9/15 [00:19<00:11,  1.94s/it]Both `max_new_tokens` (=2048) and `max_length`(=8192) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)

 67%|██████▋   | 10/15 [00:20<00:09,  1.92s/it]Both `max_new_tokens` (=2048) and `max_length`(=8192) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)

 73%|███████▎  | 11/15 [00:22<00:06,  1.74s/it]Both `max_new_tokens` (=2048) and `max_length`(=8192) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)

 80%|████████  | 12/15 [00:24<00:05,  1.78s/it]Both `max_new_tokens` (=2048) and `max_length`(=8192) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)

 87%|████████▋ | 13/15 [00:27<00:04,  2.11s/it]Both `max_new_tokens` (=2048) and `max_length`(=8192) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)

 93%|█████████▎| 14/15 [00:28<00:02,  2.02s/it]Both `max_new_tokens` (=2048) and `max_length`(=8192) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)

100%|██████████| 15/15 [00:30<00:00,  1.99s/it]
100%|██████████| 15/15 [00:30<00:00,  2.05s/it]
