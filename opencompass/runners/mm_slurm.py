import os.path as osp
import subprocess
from typing import Any, Dict, List, Tuple

import mmengine
from mmengine.utils import track_parallel_progress

from opencompass.registry import RUNNERS

from .base import BaseRunner


@RUNNERS.register_module()
class MMSlurmRunner(BaseRunner):
    """Distributed runner based on Slurm. It will launch tasks in parallel
    using `srun` command.

    Args:
        task (ConfigDict): Task type config.
        max_num_workers (int): Max number of workers to run in parallel.
            Defaults to 32.
        retry (int): Number of retries if the job failed. Defaults to 2.
        partition (str): Slurm partition name. Defaults to None.
        quotatype (str): Slurm quota type. Defaults to None.
        debug (bool): Whether to run in debug mode. Defaults to False.
        lark_bot_url (str): Lark bot url. Defaults to None.
        gpus_per_task (int): How many gpus used to run each task.
            Defaults to 8.
    """

    def __init__(self,
                 max_num_workers: int = 32,
                 retry: int = 2,
                 partition: str = None,
                 quotatype: str = None,
                 debug: bool = False,
                 gpus_per_task: int = 8):
        super().__init__(task=None, debug=debug, lark_bot_url=None)
        self.max_num_workers = max_num_workers
        self.retry = retry
        self.partition = partition
        self.quotatype = quotatype
        self.gpus_per_task = gpus_per_task

    def __call__(self, tasks: List[str], args):
        """Launch multiple tasks and summarize the results."""
        tasks = [(task, args) for task in tasks]
        status = self.launch(tasks)
        self.summarize(status)

    def launch(self, tasks: List[Dict[str, Any]]) -> List[Tuple[str, int]]:
        """Launch multiple tasks.

        Args:
            tasks (list[dict]): A list of task configs, usually generated by
                Partitioner.

        Returns:
            list[tuple[str, int]]: A list of (task name, exit code).
        """
        if not self.debug:
            status = track_parallel_progress(self._launch,
                                             tasks,
                                             nproc=self.max_num_workers,
                                             keep_order=True)
        else:
            status = [self._launch(task) for task in tasks]
        return status

    def _launch(self, task) -> int:
        config_file, args = task
        # Schedule tasks
        if self.gpus_per_task >= 8 and self.gpus_per_task % 8 == 0:
            gpu_per_node = 8
        elif self.gpus_per_task >= 8 and self.gpus_per_task % 8 != 0:
            gpu_per_node = 1
        elif self.gpus_per_task < 8:
            gpu_per_node = self.gpus_per_task

        command = (f'NCCL_SOCKET_IFNAME=eth0 '
                   f'GPUS={self.gpus_per_task} GPUS_PER_NODE={gpu_per_node} '
                   f'SRUN_ARGS="--quotatype={self.quotatype}" '
                   f'bash opencompass/multimodal/inference_slurm.sh '
                   f'{self.partition} test '
                   f'{config_file}')
        args.work_dir = args.work_dir if args.work_dir is not None else './work_dirs'  # noqa E501
        out_path = osp.join(
            args.work_dir, f'{osp.splitext(osp.basename(config_file))[0]}.out')
        task_name = f'{osp.splitext(osp.basename(config_file))[0]}'
        mmengine.mkdir_or_exist(osp.split(out_path)[0])
        err_path = out_path.replace('.out', '.err')
        mmengine.mkdir_or_exist(osp.split(err_path)[0])
        stdout = open(out_path, 'w')
        stderr = open(err_path, 'w')
        result = subprocess.run(command,
                                shell=True,
                                text=True,
                                stdout=stdout,
                                stderr=stderr)

        retry = self.retry
        while result.returncode != 0 and retry > 0:
            retry -= 1
            result = subprocess.run(command,
                                    shell=True,
                                    text=True,
                                    stdout=stdout,
                                    stderr=stderr)
        return task_name, result.returncode
